{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s83gizuO-rAf"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain openai langchain-openai langchain_google_genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z86YJ35zWlaB"
      },
      "source": [
        "## LLM 기본 실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJlUIPRgMqOj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"키를 입력해주세요\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"키를 입력해주세요\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "N6aWslhRNEEd"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "yqkh7ERYOQ2K",
        "outputId": "0c40c09f-6a03-4327-d641-84dd27234d32"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "AI는 현재 매우 다양한 작업을 수행할 수 있으며, 그 능력은 계속 발전하고 있습니다. 몇 가지 주요 분야와 예시를 들어 설명해 드릴게요.\n",
              "\n",
              "**1. 정보 처리 및 분석:**\n",
              "\n",
              "*   **데이터 분석:** 방대한 양의 데이터를 분석하여 패턴을 발견하고 예측 모델을 만들 수 있습니다. 예를 들어, 주식 시장 예측, 소비자 행동 분석, 질병 발병 예측 등에 활용됩니다.\n",
              "*   **정보 검색:** 웹 검색 엔진처럼 사용자가 원하는 정보를 빠르게 찾도록 돕습니다. 논문 검색, 뉴스 검색, 특정 주제에 대한 정보 요약 등이 가능합니다.\n",
              "*   **자연어 처리(NLP):** 인간의 언어를 이해하고 생성하는 능력입니다. 텍스트 번역, 챗봇, 음성 인식, 감성 분석 등에 사용됩니다.\n",
              "\n",
              "**2. 자동화 및 제어:**\n",
              "\n",
              "*   **자동화 시스템:** 반복적인 작업을 자동화하여 효율성을 높입니다. 공장 자동화, 로봇 청소기, 자율 주행 자동차 등이 그 예시입니다.\n",
              "*   **최적화:** 복잡한 시스템의 효율성을 극대화합니다. 물류 최적화, 에너지 소비 최적화, 생산 계획 최적화 등에 활용됩니다.\n",
              "*   **제어 시스템:** 특정 목표를 달성하기 위해 시스템을 제어합니다. 스마트 홈 시스템, 항공기 자동 조종 시스템, 산업용 로봇 제어 등이 있습니다.\n",
              "\n",
              "**3. 창작 및 예술:**\n",
              "\n",
              "*   **이미지 생성:** 텍스트 설명을 기반으로 이미지를 생성하거나, 기존 이미지를 변형할 수 있습니다.\n",
              "*   **음악 작곡:** 특정 스타일의 음악을 자동으로 작곡하거나, 사용자의 취향에 맞는 음악을 추천할 수 있습니다.\n",
              "*   **글쓰기:** 시, 소설, 에세이 등 다양한 장르의 글을 생성할 수 있습니다.\n",
              "*   **디자인:** 제품 디자인, 건축 디자인, 웹 디자인 등 다양한 분야에서 디자인을 지원할 수 있습니다.\n",
              "\n",
              "**4. 의사 결정 지원:**\n",
              "\n",
              "*   **추천 시스템:** 사용자에게 맞춤형 상품, 콘텐츠, 서비스를 추천합니다. 전자 상거래 추천, 영화 추천, 뉴스 추천 등이 있습니다.\n",
              "*   **위험 평가:** 다양한 요소를 분석하여 위험을 평가하고 예측합니다. 금융 위험 평가, 신용 위험 평가, 보안 위험 평가 등이 있습니다.\n",
              "*   **진단 및 예측:** 의료 분야에서 질병을 진단하고 예측하는 데 도움을 줍니다. 암 진단, 심장 질환 예측, 전염병 확산 예측 등이 있습니다.\n",
              "\n",
              "**5. 학습 및 적응:**\n",
              "\n",
              "*   **머신 러닝:** 데이터를 통해 스스로 학습하고 성능을 개선하는 능력입니다.\n",
              "*   **딥 러닝:** 인공 신경망을 사용하여 복잡한 패턴을 학습하고 인식하는 기술입니다. 이미지 인식, 음성 인식, 자연어 처리 등에 사용됩니다.\n",
              "*   **강화 학습:** 시행착오를 통해 최적의 행동을 학습하는 방법입니다. 게임 AI, 로봇 제어, 자율 주행 등에 사용됩니다.\n",
              "\n",
              "**더 구체적인 예시:**\n",
              "\n",
              "*   **스팸 메일 필터:** 메일 내용을 분석하여 스팸 메일을 자동으로 분류합니다.\n",
              "*   **음성 비서(Siri, Alexa 등):** 음성 명령을 이해하고 응답하며 다양한 작업을 수행합니다.\n",
              "*   **자동 번역기(Google 번역 등):** 텍스트를 다른 언어로 자동으로 번역합니다.\n",
              "*   **자율 주행 자동차:** 운전자 없이 스스로 주행합니다.\n",
              "*   **의료 영상 분석:** X-ray, MRI 등의 의료 영상을 분석하여 질병을 진단합니다.\n",
              "*   **금융 사기 탐지:** 비정상적인 거래 패턴을 감지하여 금융 사기를 예방합니다.\n",
              "*   **고객 서비스 챗봇:** 고객 문의에 자동으로 응답하고 문제를 해결합니다.\n",
              "\n",
              "이 외에도 AI는 우리가 상상하는 것 이상으로 많은 분야에서 활용되고 있으며, 앞으로 더욱 발전된 모습으로 우리 삶에 깊숙이 자리 잡을 것으로 예상됩니다. 특정 분야에 대해 더 궁금한 점이 있다면 언제든지 질문해주세요."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "ai_msg = llm.invoke(\"AI는 무엇을 할 수 있어?\")\n",
        "Markdown(ai_msg.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "collapsed": true,
        "id": "u2DOWawvOhgh",
        "outputId": "f0771e87-2def-4601-9476-41e53aad71bf"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "AI는 현재 다양한 분야에서 놀라운 능력을 보여주고 있으며, 그 능력은 계속해서 발전하고 있습니다. AI가 할 수 있는 몇 가지 주요 기능과 예시를 자세히 알려드릴게요.\n",
              "\n",
              "**1. 정보 처리 및 분석:**\n",
              "\n",
              "*   **데이터 분석:** 방대한 양의 데이터를 분석하여 패턴, 추세, 상관관계를 파악합니다.\n",
              "    *   예시: 금융 시장 분석, 소셜 미디어 트렌드 분석, 과학 연구 데이터 분석\n",
              "*   **자연어 처리(NLP):** 인간의 언어를 이해하고 생성, 번역, 요약합니다.\n",
              "    *   예시: 챗봇, 음성 비서, 기계 번역, 텍스트 요약\n",
              "*   **검색 및 정보 검색:** 사용자의 질문에 대해 관련 정보를 검색하고 제공합니다.\n",
              "    *   예시: 웹 검색 엔진, 지능형 개인 비서\n",
              "\n",
              "**2. 문제 해결 및 의사 결정:**\n",
              "\n",
              "*   **추론 및 예측:** 주어진 정보를 바탕으로 논리적인 추론을 수행하고 미래를 예측합니다.\n",
              "    *   예시: 신용 위험 평가, 수요 예측, 질병 진단\n",
              "*   **최적화:** 특정 목표를 달성하기 위한 최적의 해결책을 찾습니다.\n",
              "    *   예시: 물류 경로 최적화, 생산 일정 최적화, 포트폴리오 최적화\n",
              "*   **자동화:** 반복적이고 단순한 작업을 자동으로 수행합니다.\n",
              "    *   예시: 이메일 분류, 데이터 입력, 로봇 공학\n",
              "\n",
              "**3. 학습 및 적응:**\n",
              "\n",
              "*   **머신 러닝(ML):** 데이터를 통해 스스로 학습하고 성능을 향상시킵니다.\n",
              "    *   예시: 스팸 메일 필터, 추천 시스템, 사기 탐지\n",
              "*   **딥 러닝(DL):** 인공 신경망을 사용하여 복잡한 패턴을 학습합니다.\n",
              "    *   예시: 이미지 인식, 음성 인식, 자연어 처리\n",
              "*   **강화 학습(RL):** 시행착오를 통해 보상을 최대화하는 방법을 학습합니다.\n",
              "    *   예시: 게임 AI, 로봇 제어, 자율 주행\n",
              "\n",
              "**4. 창작 및 예술:**\n",
              "\n",
              "*   **이미지 생성:** 텍스트 설명을 기반으로 이미지를 생성하거나 기존 이미지를 변환합니다.\n",
              "    *   예시: AI 그림 생성, 사진 스타일 변환\n",
              "*   **음악 생성:** 특정 스타일이나 분위기의 음악을 작곡합니다.\n",
              "    *   예시: AI 작곡, 자동 반주\n",
              "*   **텍스트 생성:** 시, 소설, 대본 등 다양한 종류의 텍스트를 생성합니다.\n",
              "    *   예시: AI 시인, 챗봇 스토리텔링\n",
              "\n",
              "**5. 특정 분야 전문 지식:**\n",
              "\n",
              "*   **의료:** 질병 진단, 치료법 개발, 환자 모니터링\n",
              "*   **금융:** 사기 탐지, 신용 평가, 투자 자문\n",
              "*   **교육:** 맞춤형 학습, 자동 채점, 학습 분석\n",
              "*   **제조:** 품질 관리, 생산 최적화, 로봇 자동화\n",
              "*   **고객 서비스:** 챗봇 상담, 자동 응답, 고객 분석\n",
              "\n",
              "**주의해야 할 점:**\n",
              "\n",
              "*   AI는 아직 완벽하지 않으며, 오류를 범할 수 있습니다.\n",
              "*   AI는 데이터에 의존적이며, 편향된 데이터는 편향된 결과를 초래할 수 있습니다.\n",
              "*   AI의 윤리적 문제 (ex. 일자리 감소, 개인 정보 침해)에 대한 논의가 필요합니다.\n",
              "\n",
              "궁금한 점이나 더 자세한 설명이 필요하면 언제든지 물어보세요! 특정 분야나 AI 기술에 대해 더 자세히 알고 싶다면 알려주세요."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_msg = llm.invoke(\"AI는 무엇을 할 수 있어?\")\n",
        "Markdown(ai_msg.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "lz7D1-k4PI5U",
        "outputId": "b59c25bc-9854-4d3f-db35-82dc589191a4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nAI는 다양한 작업을 수행할 수 있습니다. 예를 들어, 이미지 인식, 음성 인식, 자연어 처리, 예측 분석, 자율 주행 등 다양한 분야에서 활용될 수 있습니다. 또한, AI는 데이터를 분석하고 패턴을 학습하여 문제를 해결하거나 결정을 내릴 수 있습니다. 또한, AI는 인간의 지능을 모방하여 문제를 해결하고, 새로운 지식을 습득하고, 창의적인 작업을 수행할 수도 있습니다.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import OpenAI\n",
        "openai_llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\" ,temperature=0 , streaming=True)\n",
        "ai_msg = openai_llm.invoke(\"AI는 무엇을 할 수 있어?\")\n",
        "ai_msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1dl40S6P6wN",
        "outputId": "620b3cc0-2194-41d9-e95d-78c634897562"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Unexpected argument 'streaming' provided to ChatGoogleGenerativeAI. Did you mean: 'disable_streaming'?\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: UserWarning: WARNING! streaming is not default parameter.\n",
            "                streaming was transferred to model_kwargs.\n",
            "                Please confirm that streaming is what you intended.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0,\n",
        "    streaming=True\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "woHbiS2GRQxQ",
        "outputId": "2992437e-ed53-4c5e-8bac-fe27022dd07c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AI는 정말 다양한 일을 할 수 있습니다! 간단하게 몇 가지 주요 분야와 예시를 들어 설명해 드릴게요.\\n\\n**1. 정보 처리 및 분석:**\\n\\n*   **검색 엔진:** 방대한 데이터를 분석하여 사용자가 원하는 정보를 빠르게 찾아줍니다. (예: Google, Bing)\\n*   **데이터 분석:** 복잡한 데이터를 분석하여 패턴을 발견하고 예측 모델을 만듭니다. (예: 주식 시장 예측, 고객 행동 분석)\\n*   **자연어 처리 (NLP):** 인간의 언어를 이해하고 분석하여 번역, 챗봇, 텍스트 요약 등에 활용됩니다. (예: Google 번역, Siri, ChatGPT)\\n\\n**2. 자동화:**\\n\\n*   **로봇 공학:** 공장 자동화, 물류, 의료 등 다양한 분야에서 사람을 대신하여 작업을 수행합니다. (예: 자동차 생산 로봇, 수술 로봇)\\n*   **업무 자동화 (RPA):** 반복적인 사무 업무를 자동화하여 효율성을 높입니다. (예: 송장 처리, 데이터 입력)\\n*   **자율 주행:** 운전자의 개입 없이 스스로 주행하는 자동차를 개발합니다. (예: Tesla, Waymo)\\n\\n**3. 창작:**\\n\\n*   **이미지 생성:** 텍스트 설명을 기반으로 새로운 이미지를 생성합니다. (예: DALL-E 2, Midjourney)\\n*   **음악 작곡:** 다양한 스타일의 음악을 자동으로 작곡합니다. (예: Amper Music, Jukebox)\\n*   **글쓰기:** 기사, 시, 소설 등 다양한 형태의 글을 생성합니다. (예: GPT-3)\\n\\n**4. 의사 결정 지원:**\\n\\n*   **추천 시스템:** 사용자에게 맞춤형 상품, 콘텐츠, 서비스를 추천합니다. (예: Netflix, YouTube)\\n*   **의료 진단:** 의료 데이터를 분석하여 질병을 진단하고 치료 방법을 제시합니다. (예: IBM Watson Health)\\n*   **금융 분석:** 시장 상황을 분석하여 투자 결정을 돕습니다. (예: BlackRock Aladdin)\\n\\n**5. 학습 및 적응:**\\n\\n*   **머신 러닝:** 데이터를 통해 스스로 학습하고 성능을 향상시킵니다. (예: 스팸 메일 필터, 신용 사기 탐지)\\n*   **강화 학습:** 시행착오를 통해 최적의 행동 전략을 학습합니다. (예: 게임 AI, 로봇 제어)\\n\\n**더 구체적인 예시:**\\n\\n*   **스마트 스피커 (Amazon Echo, Google Home):** 음성 명령을 이해하고 음악 재생, 알람 설정, 정보 검색 등을 수행합니다.\\n*   **챗봇:** 고객 문의에 자동으로 응답하고 문제를 해결합니다.\\n*   **얼굴 인식:** 보안 시스템, 출입 통제, 사진 정리 등에 활용됩니다.\\n*   **게임 AI:** 게임 캐릭터를 제어하고 플레이어와 경쟁합니다.\\n\\n**주의할 점:**\\n\\n*   AI는 아직 완벽하지 않으며, 오류를 범할 수 있습니다.\\n*   AI의 발전은 윤리적인 문제와 사회적인 영향을 고려해야 합니다.\\n\\n궁금한 점이 있다면 언제든지 다시 질문해주세요! 어떤 분야에 대해 더 자세히 알고 싶으신가요?'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_msg = llm.invoke(\"AI는 무엇을 할 수 있어?\")\n",
        "ai_msg.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vpH5dI7RcZa",
        "outputId": "d118af3c-d897-4397-c868-ddc7ca433882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI|는 정말| 다양한 일을 할 수 있습니다! 간단하게 몇 가지 주요 분야와 예시를 들어| 설명해 드릴게요.\n",
            "\n",
            "**1. 정보 처리 및 분석:**\n",
            "\n",
            "*|   **검색 엔진:** 방대한 데이터를 분석하여 사용자가 원하는 정보를 빠르게 찾아줍니다. (예: Google, Bing)\n",
            "*   **데이터 분석:** 복|잡한 데이터를 분석하여 패턴을 발견하고 예측 모델을 만듭니다. (예: 시장 예측, 위험 관리)\n",
            "*   **자연어 처리 (|NLP):** 인간의 언어를 이해하고 생성하여 번역, 챗봇, 텍스트 요약 등에 활용됩니다. (예: Google 번역, Siri, ChatGPT)\n",
            "\n",
            "**2. 자동화 및 제어:**\n",
            "\n",
            "*|   **로봇 공학:** 로봇을 제어하여 반복적인 작업이나 위험한 작업을 수행합니다. (예: 공장 자동화, 수술 로봇)\n",
            "*   **자율 주행:** 운전자의| 개입 없이 차량을 운전합니다. (예: Tesla, Waymo)\n",
            "*   **스마트 홈:** 가전제품을 제어하고 에너지 소비를 최적화합니다. (예: Amazon Echo, Google Home)\n",
            "\n",
            "**3. 창작 및 예술:**\n",
            "\n",
            "*   **이미지 생성:** |텍스트 설명을 기반으로 이미지를 생성합니다. (예: DALL-E, Midjourney)\n",
            "*   **음악 작곡:** 새로운 음악을 작곡하거나 기존 음악을 편곡합니다. (예: Amper Music, Jukebox)\n",
            "*   **글쓰기:** 기사, 시|, 소설 등 다양한 형태의 글을 작성합니다. (예: GPT-3)\n",
            "\n",
            "**4. 의사 결정 지원:**\n",
            "\n",
            "*   **추천 시스템:** 사용자의 선호도를 분석하여 상품, 영화, 음악 등을 추천합니다. (예: Netflix, Amazon)\n",
            "*   **금융| 분석:** 주식 시장 데이터를 분석하여 투자 결정을 돕습니다. (예: Bloomberg Terminal)\n",
            "*   **의료 진단:** 의료 이미지를 분석하여 질병을 진단하고 치료 계획을 수립합니다. (예: IBM Watson Health)\n",
            "\n",
            "**5. 학습 및 적응:**\n",
            "\n",
            "*|   **머신 러닝:** 데이터를 통해 스스로 학습하고 성능을 향상시킵니다. (예: 스팸 필터, 사기 탐지)\n",
            "*   **강화 학습:** 시행착오를 통해 최적의 행동 전략을 학습합니다. (예: 게임 AI, 로봇 제|어)\n",
            "\n",
            "**더 자세한 예시:**\n",
            "\n",
            "*   **고객 서비스:** 챗봇을 통해 24시간 고객 문의에 응대합니다.\n",
            "*   **보안:** 얼굴 인식 기술을 사용하여 출입 통제를 강화합니다.\n",
            "*   **교육:** 학생 개개인의 학습 스타|일에 맞춰 맞춤형 교육 콘텐츠를 제공합니다.\n",
            "*   **농업:** 드론을 사용하여 농작물의 상태를 모니터링하고 수확량을 예측합니다.\n",
            "\n",
            "이 외에도 AI는 정말 다양한 분야에서 활용되고 있으며, 그 가능성은 무궁무진합니다. 혹시 특정 분야에| 대해 더 궁금한 점이 있으시면 언제든지 질문해주세요!\n",
            "|"
          ]
        }
      ],
      "source": [
        "# ai_msg = llm.invoke(\"AI는 무엇을 할 수 있어?\")\n",
        "from IPython.display import display, Markdown\n",
        "for chunk in llm.stream(\"AI는 무엇을 할 수 있어?\"):\n",
        "    print(chunk.content, end=\"|\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pwxTK-GWthi"
      },
      "source": [
        "## PromptTemplate실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MFbO2SpCSlbk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import OpenAI , ChatOpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrN1khHsXJMb"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"키를 입력해주세요\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8-YXLoM2XT5G"
      },
      "outputs": [],
      "source": [
        "openai_1 = OpenAI(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    temperature=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hux8o-IYYnhj"
      },
      "source": [
        "### PromtTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMcc3OPoYk5g",
        "outputId": "abd77691-4711-434c-a64c-a036a748491f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StringPromptValue(text='야구 주제로 농담을 해줘 ')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate , ChatPromptTemplate\n",
        "\n",
        "string_prompt = PromptTemplate.from_template(\"{subject} 주제로 농담을 해줘 \")\n",
        "\n",
        "string_prompt_value = string_prompt.format_prompt(subject=\"야구\")\n",
        "string_prompt_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQOJuhiAZDMY",
        "outputId": "4a11ea36-c4e1-4037-9794-07e2cd685d31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='야구 주제로 농담을 해줘 ', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_prompt = ChatPromptTemplate.from_template(\"{subject} 주제로 농담을 해줘 \")\n",
        "chat_prompt_value = chat_prompt.format_prompt(subject=\"야구\")\n",
        "chat_prompt_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "zUC6Qob4Yyuy"
      },
      "outputs": [],
      "source": [
        "# prompttemplate 활용\n",
        "from langchain.prompts import PromptTemplate , ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "당신은 웃긴말을 잘 하는 개그맨이야, 내가 알려주는 소재로 재미있는 개그를 만들어 줘!\n",
        "재미없으면 패널티를 줄거야!!\n",
        "소재는 아래와 같다.\n",
        "\n",
        "<소재>\n",
        "{소재}\n",
        "\"\"\"\n",
        "commic_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"소재\"],\n",
        "    template=template\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJgYEUxicX-a",
        "outputId": "2bcbf569-dae8-448a-ffa1-435a4174709b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "당신은 웃긴말을 잘 하는 개그맨이야, 내가 알려주는 소재로 재미있는 개그를 만들어 줘!\n",
            "재미없으면 패널티를 줄거야!!\n",
            "소재는 아래와 같다.\n",
            "\n",
            "<소재>\n",
            "야구\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(commic_prompt_template.format(소재=\"야구\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "O2tlDxkUcfQF",
        "outputId": "315ed226-4a0b-4d7b-82ae-44fa86fd5e01"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'고양이\\n토끼\\n사자\\n\\n\"강아지가 고양이한테 물려고 하면 어떻게 할까? 당연히 토끼를 찾아서 사자한테 물려줘야지!\"'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai_1(commic_prompt_template.format(소재=\"강아지\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "MlPDOm3oc63E"
      },
      "outputs": [],
      "source": [
        "# prompttemplate 활용\n",
        "from langchain.prompts import PromptTemplate , ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "당신은 20년상의 요리경력을 가진 요리사야, 내가 알려주는 재료로 맛있는 음식을 만들어 줘!\n",
        "재료는 아래와 같다.\n",
        "\n",
        "<재료>\n",
        "{재료}\n",
        "\"\"\"\n",
        "cooking_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"재료\"],\n",
        "    template=template\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "yuZH9Rfidnlh",
        "outputId": "36966deb-9c32-4f2a-e4b0-95eae2ff791a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n당신은 계란과 빵으로 맛있는 계란토스트를 만들 수 있을 것 같아요. 먼저 빵을 토스트기에 넣어서 바삭하게 구워주세요. 그리고 계란을 풀어서 소금과 후추로 간을 해주세요. 그리고 버터를 팬에 녹여서 계란을 부드럽게 익혀주세요. 그리고 파를 다듬어서 계란 위에 올려주면 완성입니다. 계란토스트는 아침 식사로도 좋고 간단한 간식으로도 좋아요. 맛있게 즐겨주세요!'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai_1(cooking_prompt_template.format(재료=\"계란, 빵, 파, 버터\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqUn1MLhdwty"
      },
      "source": [
        "\n",
        "### ChatPrompt 활용\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7TbK-L3pe3is"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Lm8aw3kTfh1P"
      },
      "outputs": [],
      "source": [
        "chatgpt = OpenAI(\n",
        "    temperature=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "KVYuwNh7f4-A",
        "outputId": "1df6bb1a-f375-41b3-b1b3-3ad1cdf46c5d"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'재료'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-3f48bad15099>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mchat_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msystem_message_prompt\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mhumman_message_prompt\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mchat_prompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingredients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhuman_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchatgpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_prompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m재료\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"계란, 빵, 파, 버터\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/prompts/chat.py\u001b[0m in \u001b[0;36mformat_prompt\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mPromptValue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \"\"\"\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mChatPromptValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/prompts/chat.py\u001b[0m in \u001b[0;36mformat_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mmessage_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseMessagePromptTemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseChatPromptTemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             ):\n\u001b[0;32m-> 1186\u001b[0;31m                 \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage_template\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/prompts/chat.py\u001b[0m in \u001b[0;36mformat_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mBaseMessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \"\"\"\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maformat_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/prompts/chat.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \"\"\"\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringPromptTemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m             return self._msg_class(\n\u001b[1;32m    593\u001b[0m                 \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madditional_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/prompts/prompt.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m    185\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_partial_and_user_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDEFAULT_FORMATTER_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemplate_format\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/string.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFormatter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/formatting.py\u001b[0m in \u001b[0;36mvformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m             )\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     def validate_input_variables(\n",
            "\u001b[0;32m/usr/lib/python3.11/string.py\u001b[0m in \u001b[0;36mvformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mused_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_unused_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/string.py\u001b[0m in \u001b[0;36m_vformat\u001b[0;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# given the field_name, find the object it references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;31m#  and the argument it came from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_used\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0mused_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_used\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/string.py\u001b[0m in \u001b[0;36mget_field\u001b[0;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter_field_name_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# loop through the rest of the field_name, doing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/string.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, key, args, kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '재료'"
          ]
        }
      ],
      "source": [
        "template = \"\"\"\n",
        "당신은 20년상의 요리경력을 가진 요리사야, 내가 알려주는 재료로 맛있는 음식을 만들어 줘!\n",
        "재료는 아래와 같다.\n",
        "\n",
        "<재료>\n",
        "{재료}\n",
        "\"\"\"\n",
        "\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "# 질문을 던지는 사람의 매개변수\n",
        "human_template = \"{재료}\"\n",
        "humman_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt ,humman_message_prompt ])\n",
        "chat_prompt.format_prompt(ingredients=human_template).to_messages()\n",
        "answer = chatgpt(chat_prompt.format_prompt(재료=\"계란, 빵, 파, 버터\").to_messages())\n",
        "answer.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "N51PGuG6hVVg",
        "outputId": "5342f6c8-0db9-4c89-ba02-badb2fbb9348"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-61-f3eb04ad9b1c>:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  chat_model = ChatOpenAI(temperature=0.7)  # You can adjust temperature as needed\n",
            "<ipython-input-61-f3eb04ad9b1c>:34: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = chat_model(formatted_prompt)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'주어진 재료로는 맛있는 계란 토스트를 만들어 볼 수 있어요!\\n\\n**계란 토스트 레시피:**\\n1. 팬에 버터를 녹여줍니다.\\n2. 계란을 풀어 볼에 푼 후 소금과 후추로 간을 해줍니다.\\n3. 빵을 토스트 해줍니다.\\n4. 다시 팬에 버터를 녹여 계란을 부어 계란지단을 만들어줍니다.\\n5. 계란지단을 빵 위에 얹어줍니다.\\n6. 파를 잘게 다져서 계란 토스트 위에 올려주면 완성!\\n\\n맛있는 계란 토스트가 완성되었어요. 즐겁게 식사하세요!'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# Initialize the chat model\n",
        "chat_model = ChatOpenAI(temperature=0.7)  # You can adjust temperature as needed\n",
        "\n",
        "# Create the system message template for the cooking assistant\n",
        "system_template = \"\"\"\n",
        "당신은 20년상의 요리경력을 가진 요리사야, 내가 알려주는 재료로 맛있는 음식을 만들어 줘!\n",
        "재료는 아래와 같다.\n",
        "\n",
        "<재료>\n",
        "{ingredients}\n",
        "</재료>\n",
        "\"\"\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "# Create the human message template\n",
        "human_template = \"이 재료들로 요리할 수 있는 음식을 알려주세요.\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "# Combine the messages into a chat prompt\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    system_message_prompt,\n",
        "    human_message_prompt\n",
        "])\n",
        "\n",
        "# Function to get cooking recommendations\n",
        "def get_cooking_recommendation(ingredients):\n",
        "    # Format the prompt with the ingredients\n",
        "    formatted_prompt = chat_prompt.format_prompt(ingredients=ingredients).to_messages()\n",
        "\n",
        "    # Get response from the model\n",
        "    response = chat_model(formatted_prompt)\n",
        "\n",
        "    return response.content\n",
        "ingredients = \"계란, 빵, 파, 버터\"\n",
        "get_cooking_recommendation(ingredients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo8l7jduk9Gz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "JVmo1N7rj4JN",
        "outputId": "bb888bfa-d299-44ec-f2fb-638fbec54302"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "종목: 삼성전자\n",
              "\n",
              "최근 1개월간의 RSI(상대강도지수)를 계산해 보겠습니다.\n",
              "\n",
              "일별 종가 데이터를 바탕으로 RSI를 계산하였고, 계산 결과는 다음과 같습니다.\n",
              "\n",
              "- 1일 전 RSI: 60\n",
              "- 2일 전 RSI: 55\n",
              "- 3일 전 RSI: 58\n",
              "- 4일 전 RSI: 62\n",
              "- 5일 전 RSI: 65\n",
              "- 6일 전 RSI: 70\n",
              "- 7일 전 RSI: 75\n",
              "- 8일 전 RSI: 80\n",
              "- 9일 전 RSI: 85\n",
              "- 10일 전 RSI: 90\n",
              "- 11일 전 RSI: 85\n",
              "- 12일 전 RSI: 80\n",
              "- 13일 전 RSI: 75\n",
              "- 14일 전 RSI: 70\n",
              "- 15일 전 RSI: 65\n",
              "- 16일 전 RSI: 60\n",
              "- 17일 전 RSI: 55\n",
              "- 18일 전 RSI: 50\n",
              "- 19일 전 RSI: 45\n",
              "- 20일 전 RSI: 40\n",
              "- 21일 전 RSI: 35\n",
              "- 22일 전 RSI: 30\n",
              "- 23일 전 RSI: 25\n",
              "- 24일 전 RSI: 20\n",
              "- 25일 전 RSI: 15\n",
              "- 26일 전 RSI: 10\n",
              "- 27일 전 RSI: 5\n",
              "- 28일 전 RSI: 0\n",
              "\n",
              "위 데이터를 종합해보면, 삼성전자 주식의 RSI는 최근 1개월 동안 30에서 70 사이를 주로 유지하다가 가끔 70을 넘어서는 과매수 상태에 진입하는 경향을 보이고 있습니다. 따라서 단기적으로는 조정이 예상될 수 있습니다. 종합적으로 판단하면 현재 삼성전자 주식은 중립적인 상태로 평가될 수 있습니다."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# Initialize the chat model\n",
        "chat_model = ChatOpenAI(temperature=0.2)  # You can adjust temperature as needed\n",
        "\n",
        "# Create the system message template for the cooking assistant\n",
        "system_template = \"\"\"\n",
        "당신은 20년상의 주식의 기술지표 분석 전문가야, 내가 알려주는 종목으로 최근 1개월동안의 RSI 지표를 계산해서 만들어줘!\n",
        "종목은 아래와 같다.\n",
        "\n",
        "<종목>\n",
        "{ingredients}\n",
        "</종목>\n",
        "\"\"\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "# Create the human message template\n",
        "human_template = \"이 종목을 분석해 주세요\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "# Combine the messages into a chat prompt\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    system_message_prompt,\n",
        "    human_message_prompt\n",
        "])\n",
        "\n",
        "# Function to get cooking recommendations\n",
        "def get_cooking_recommendation(ingredients):\n",
        "    # Format the prompt with the ingredients\n",
        "    formatted_prompt = chat_prompt.format_prompt(ingredients=ingredients).to_messages()\n",
        "\n",
        "    # Get response from the model\n",
        "    response = chat_model(formatted_prompt)\n",
        "\n",
        "    return response.content\n",
        "ingredients = \"삼성전자\"\n",
        "Markdown(get_cooking_recommendation(ingredients))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9Xelvtz9Ea5"
      },
      "source": [
        "### Few-shot 을 이용한 prompttemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Gc3LiM7blnsK"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "exampes = [\n",
        "    {\n",
        "        \"question\" : \"아이유로 삼행시 만들어줘\",\n",
        "        \"answer\" : '''\n",
        "          아 : 아이유는\n",
        "          이 : 이유가 없는 아이다\n",
        "          유 : 유아스러우니까\n",
        "        '''\n",
        "    },\n",
        "     {\n",
        "        \"question\" : \"김민수로 삼행시 만들어줘\",\n",
        "        \"answer\" : '''\n",
        "          김 : 김치는 맛있다.\n",
        "          민 : 민수가 좋아하니까?\n",
        "          수 : 수억을 줘도 안바꿔\n",
        "        '''\n",
        "    },\n",
        "\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sQoBycx-UhK",
        "outputId": "fb0c4fe2-510d-442b-fffa-bb782a433064"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-80-d2964bc4d0d7>:1: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(openai_1.predict(\"호날두로 삼행시를 만들어줘\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "오늘은 축구의 왕이 태어난 날\n",
            "그 이름은 크리스티아누 호날두\n",
            "그의 발로는 골망을 뚫어내고\n",
            "세계를 놀라게 만들어주네\n",
            "\n",
            "그의 기량은 누구도 따라올 수 없어\n",
            "매 경기마다 빛나는 그의 모습\n",
            "팬들은 그를 보며 눈을 뜨고\n",
            "그의 활약에 또 한 번 놀라네\n",
            "\n",
            "호날두는 축구의 신이라 불리고\n",
            "그의 명성은 세계를 넘어서네\n",
            "그의 골은 마치 예술작품 같아\n",
            "세계를 놀라게 만들어주네\n",
            "\n",
            "오늘도 호날두는 그의 발로\n",
            "축구의 역사를 새로 쓰네\n",
            "그의 이름은\n"
          ]
        }
      ],
      "source": [
        "print(openai_1.predict(\"호날두로 삼행시를 만들어줘\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "tJI2Tkmq-vK4"
      },
      "outputs": [],
      "source": [
        "example_prompt = PromptTemplate(input_variables=[\"question\" , \"answer\"] , template=\"질문 : {question}\\n답변 : {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECH14bgI_K1X",
        "outputId": "0240d934-2167-4726-ebbe-d137ed2ee1b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "질문 : 아이유로 삼행시 만들어줘\n",
            "답변 : \n",
            "          아 : 아이유는\n",
            "          이 : 이유가 없는 아이다\n",
            "          유 : 유아스러우니까\n",
            "        \n",
            "\n",
            "질문 : 김민수로 삼행시 만들어줘\n",
            "답변 : \n",
            "          김 : 김치는 맛있다.\n",
            "          민 : 민수가 좋아하니까?\n",
            "          수 : 수억을 줘도 안바꿔\n",
            "        \n",
            "\n",
            "질문 : 이순신으로 삼행시 만들어줘\n",
            "답변 : \n"
          ]
        }
      ],
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "    examples=exampes,\n",
        "    example_prompt=example_prompt,\n",
        "    suffix=\"질문 : {input}\\n답변 : \",\n",
        "    input_variables=[\"input\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "print(prompt.format(input=\"이순신으로 삼행시 만들어줘\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RldHcYxaACLk",
        "outputId": "f3c6b514-d91c-4b76-857b-5cceb02c8041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "          이 : 이순신은\n",
            "          순 : 순간을 잡는다\n",
            "          신 : 신뢰할 수 있는 장군이다\n"
          ]
        }
      ],
      "source": [
        "oder_message  = prompt.format(input=\"이순신으로 삼행시 만들어줘\")\n",
        "print(openai_1.invoke(oder_message))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I7AoV0dnAVcd"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "# from langchain_community.vectorstores import Chroma\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Input: {input}\\nOutput: {output}\",\n",
        ")\n",
        "\n",
        "# These are a lot of examples of a pretend task of creating antonyms.\n",
        "examples = [\n",
        "    {\"input\": \"행복\", \"output\": \"슬픔\"},\n",
        "    {\"input\": \"흥미\", \"output\": \"지루\"},\n",
        "    {\"input\": \"불안\", \"output\": \"안정\"},\n",
        "    {\"input\": \"긴 기차\", \"output\": \"짧은 기차\"},\n",
        "    {\"input\": \"큰 공\", \"output\": \"작은 공\"},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPhWNC4gAxgZ",
        "outputId": "b550e55c-7bb0-4c1c-9fc0-7284d1858ab0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-213a6f502b3d>:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  OpenAIEmbeddings(),\n"
          ]
        }
      ],
      "source": [
        "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
        "    # This is the list of examples available to select from.\n",
        "    examples,\n",
        "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
        "    OpenAIEmbeddings(),\n",
        "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
        "    Chroma,\n",
        "    # This is the number of examples to produce.\n",
        "    k=1\n",
        ")\n",
        "similar_prompt = FewShotPromptTemplate(\n",
        "    # We provide an ExampleSelector instead of examples.\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"주어진 입력에 대해 반대의 의미를 가진 단어를 출력해줘\",\n",
        "    suffix=\"Input: {단어}\\nOutput:\",\n",
        "    input_variables=[\"단어\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_66axThIDGIZ",
        "outputId": "00e751c3-f570-41cf-ce23-7da785025816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.8)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.4)\n",
            "Requirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.9)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.21.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp6Jc1woDG-m",
        "outputId": "bea99e20-8784-4eb0-9561-c11e91953402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "주어진 입력에 대해 반대의 의미를 가진 단어를 출력해줘\n",
            "\n",
            "Input: 불안\n",
            "Output: 안정\n",
            "\n",
            "Input: 무서운\n",
            "Output:\n"
          ]
        }
      ],
      "source": [
        "# Input is a feeling, so should select the happy/sad example\n",
        "print(similar_prompt.format(단어=\"무서운\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwUVV5hTD2S5",
        "outputId": "7e8fc5ae-7d75-4913-fe83-09a86d447b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 어두운 고양이\n"
          ]
        }
      ],
      "source": [
        "query = \"밝은 돼지\"\n",
        "print(openai_1(similar_prompt.format(단어=query)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4VJog_cELJB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
